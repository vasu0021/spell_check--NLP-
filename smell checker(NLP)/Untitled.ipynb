{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd2c9204-97dc-46df-834a-e7f72c3d1088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcb12d8-1286-49e5-ac77-ee6e05b59777",
   "metadata": {},
   "source": [
    "### 1.Finding the unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5a348bf-1b8d-4ba6-8088-85874a0a0fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115585\n",
      "32198\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "with open('big.txt','r') as fd:\n",
    "    lines = fd.readlines()\n",
    "    \n",
    "    for line in lines:\n",
    "        words += re.findall(r'\\w+',line.lower())\n",
    "print(len(words))\n",
    "vocab = list(set(words))\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458a39f8-9b7f-4d2b-ab16-4c7ee9ab035d",
   "metadata": {},
   "source": [
    "### 2.finding the probability distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b6eb370-1951-4335-928f-af9b10977bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 32198/32198 [09:23<00:00, 57.16it/s]\n"
     ]
    }
   ],
   "source": [
    "word_probability = {}\n",
    "\n",
    "for word in tqdm(vocab):\n",
    "    word_probability[word] = float(words.count(word)/len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40b9d77-cef8-49de-b400-858c57395ae4",
   "metadata": {},
   "source": [
    "### 3. Text preprocessing\n",
    "splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6253f0fa-a838-44e6-bde8-1e2dba81c05d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 'vasudev'),\n",
       " ('v', 'asudev'),\n",
       " ('va', 'sudev'),\n",
       " ('vas', 'udev'),\n",
       " ('vasu', 'dev'),\n",
       " ('vasud', 'ev'),\n",
       " ('vasude', 'v'),\n",
       " ('vasudev', '')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split(word):\n",
    "    parts=[]\n",
    "    \n",
    "    for i in range (len(word)+1):\n",
    "        parts+=[(word[:i],word[i:])]\n",
    "    \n",
    "    return parts\n",
    "\n",
    "split('vasudev')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2e695e-3acd-4d34-9915-f4a56540a688",
   "metadata": {},
   "source": [
    "3.1 Delete\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40f86b78-edad-4fe6-95d6-e527d2851163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eallo', 'hallo', 'hello', 'healo', 'healo', 'heall', 'heallo']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def delete(word):\n",
    "    output = []\n",
    "    for l,r in split(word):\n",
    "        output.append(l+r[1:])\n",
    "    return output\n",
    "\n",
    "delete('heallo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4acaf9f-c0b2-4111-a277-7e22e04c4eb5",
   "metadata": {},
   "source": [
    "#3.2) swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8cbf8f4-a2d3-4654-bc58-f9b04a97c8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vloe', 'love', 'lveo']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def swap(word):\n",
    "        \n",
    "    output = []    \n",
    "    for l,r in split(word):\n",
    "        if (len(r) > 1):\n",
    "            output.append(l + r[1] + r[0] + r[2:])\n",
    "    return output\n",
    "            \n",
    "swap('lvoe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4221a8-07e3-4b60-b1af-f4f185b7d27d",
   "metadata": {},
   "source": [
    "#3.3)replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de25481a-d88c-4c13-a926-e5a54243bdd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replace(word):\n",
    "    \n",
    "    characters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    output = []    \n",
    "\n",
    "    for l,r in split(word):\n",
    "        for char in characters:\n",
    "            output.append(l + char +  r[1:])\n",
    "    return output\n",
    "\n",
    "len(replace('lave'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ffd5a8-52de-43ba-a048-03458ac986ba",
   "metadata": {},
   "source": [
    "#3.4)Insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23b8e154-0e55-4e7a-a4f5-627c19853799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alve',\n",
       " 'blve',\n",
       " 'clve',\n",
       " 'dlve',\n",
       " 'elve',\n",
       " 'flve',\n",
       " 'glve',\n",
       " 'hlve',\n",
       " 'ilve',\n",
       " 'jlve',\n",
       " 'klve',\n",
       " 'llve',\n",
       " 'mlve',\n",
       " 'nlve',\n",
       " 'olve',\n",
       " 'plve',\n",
       " 'qlve',\n",
       " 'rlve',\n",
       " 'slve',\n",
       " 'tlve',\n",
       " 'ulve',\n",
       " 'vlve',\n",
       " 'wlve',\n",
       " 'xlve',\n",
       " 'ylve',\n",
       " 'zlve']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def insert(word):\n",
    "    \n",
    "    characters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    output=[]\n",
    "        \n",
    "    for l,r in split(word):\n",
    "        for char in characters:\n",
    "            output.append(l+char+r)\n",
    "\n",
    "        return output\n",
    "\n",
    "insert('lve')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350d7578-b742-43d0-883e-e82b8225cb17",
   "metadata": {},
   "source": [
    "## 4. Finding the prediction\n",
    "### 4.1) combining possible words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d547c9ed-1b70-48ae-b41a-f3c60bc6c49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit(word):\n",
    "    return set(insert(word)+delete(word)+swap(word)+replace(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ce43dcd-ad6f-450d-84d1-9db4c9c7ca53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit(word):\n",
    "    return (insert(word)+ delete(word)+swap(word)+replace(word))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f69f33-973b-495e-8728-e3bbb491b1f0",
   "metadata": {},
   "source": [
    "## 4.2) Predicting the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7de51d3-76b5-4482-a29b-60bed41a5c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spell_check_edit_1(word, count = 5):\n",
    "    \n",
    "    output = []\n",
    "    suggested_words = edit(word)\n",
    "    \n",
    "    for wrd in suggested_words:        \n",
    "        if wrd in word_probability.keys():\n",
    "            output.append([wrd, word_probability[wrd]])\n",
    "            \n",
    "    return list(pd.DataFrame(output, columns = ['word','prob']).sort_values(by = 'prob', ascending = False).head(count)['word'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "455f3c3e-e3e8-4929-8815-499202b8f512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['family']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell_check_edit_1('famili')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6539a56-6650-436e-8e42-5fc847b2e46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'that', 'than', 'tea', 'ha']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell_check_edit_1('tha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b53b62c2-feb4-4bfb-8270-2af823bd79e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in', 'it', 'is', 'i', 'him']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell_check_edit_1('im')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c831d8e-4318-424c-b8ee-6c1e49b8304a",
   "metadata": {},
   "source": [
    "## 5. Finding the Prediction (Level - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d55d2063-ac1e-48fd-a304-069b25e2435b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['family', 'namely', 'fame', 'amelie', 'camel']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def spell_check_edit_2(word, count=5):\n",
    "    output = []\n",
    "    suggested_words = set(edit(word))  # Level one edit\n",
    "\n",
    "    for e1 in edit(word):\n",
    "        suggested_words.update(edit(e1))  # Second level edit\n",
    "\n",
    "    for wrd in suggested_words:\n",
    "        if wrd in word_probability.keys():\n",
    "            output.append([wrd, word_probability[wrd]])\n",
    "\n",
    "    return list(\n",
    "        pd.DataFrame(output, columns=['word', 'prob'])\n",
    "          .sort_values(by='prob', ascending=False)\n",
    "          .head(count)['word']\n",
    "          .values\n",
    "    )\n",
    "spell_check_edit_2('fameli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c66a998-a74c-4bd5-a17a-7d0d85b4cba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['that', 'what', 'than', 'hat', 'heat']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell_check_edit_2('thhat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c7e973-6dd3-42a6-a686-6bc1b1b86d40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
